# -*- coding: utf-8 -*-
"""apriori.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bjxx7lDObXSIH7558ugFk17HgUW84syV

# Association Analysis
## Frequent Itemset Mining using Apriori Algorithm

### Importing Libaries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
from mlxtend.frequent_patterns import apriori, association_rules
import matplotlib.pyplot as plt
# %matplotlib inline

"""### Reading Data"""

df = pd.read_csv('retail_data.csv', sep=',')

df.head(5)

"""Each row of the dataset represents items that were purchased together on the same day at same store.

The dataset is a **sparse dataset** as relatively high percentage of data is NA or NAN or equivalent.

Let's see all the unique items in the dataset.
"""

items = (df['0'].unique())
items

"""### Data Preprocessing

To make use of the apriori module given by mlxtend library, we need to convert the dataset according to it's liking.
apriori module requires a dataframe that has either 0 and 1 or True and False as data.
The data we have is all string (name of items), we need to **One Hot Encode** the data.

##### Custom One Hot Encoding
"""

encoded_vals = []
for index, row in df.iterrows():
    labels = {}
    uncommons = list(set(items) - set(row))
    commons = list(set(items).intersection(row))
    for uc in uncommons:
        labels[uc] = 0
    for com in commons:
        labels[com] = 1
    encoded_vals.append(labels)
encoded_vals

"""Let's have a look at the One Hot Encoded dataset.

"""

ohe_df = pd.DataFrame(encoded_vals)
ohe_df.head(3)

"""The first observation from original dataset:
['Bread', 'Wine','Eggs', 'Meat', 'Cheese', 'Pencil', 'Diaper']

Take a look at first observation in our one hot encoded dataframe. Do you think OHE worked?

### Applying Apriori

apriori module from mlxtend library provides fast and efficient apriori implementation.  <br>
<br>
> **apriori(df, min_support=0.5, use_colnames=False, max_len=None, verbose=0, low_memory=False)**

##### Parameters
- ` df ` : One-Hot-Encoded DataFrame or DataFrame that has 0 and 1 or True and False as values
- ` min_support ` : Floating point value between 0 and 1 that indicates the mininmum support required for an itemset to be selected. <br>
<center> $ # of observation with item / total observation $ </center>
- ` use_colnames ` : This allows to preserve column names for itemset making it more readable.
- ` max_len ` : Max length of itemset generated. If not set, all possible lengths are evaluated.
- ` verbose ` : Shows the number of iterations if >= 1 and low_memory is True. If =1 and low_memory is False , shows the number of combinations.
- ` low_memory ` : <div style="text-align:justify">If True, uses an iterator to search for combinations above min_support. Note that while low_memory=True should only be used for large dataset if memory resources are limited, because this implementation is approx. 3-6x slower than the default.</div>
"""

freq_items = apriori(ohe_df, min_support=0.2, use_colnames=True, verbose=1)
freq_items

from mlxtend.frequent_patterns import apriori, association_rules

num_itemsets = len(ohe_df)

rules = association_rules(freq_items, num_itemsets=num_itemsets, metric="confidence", min_threshold=0.6)
rules

"""### Visualizing results

1. **Support vs Confidence**
"""

plt.scatter(rules['support'], rules['confidence'], alpha=0.5)
plt.xlabel('support')
plt.ylabel('confidence')
plt.title('Support vs Confidence')
plt.show()

